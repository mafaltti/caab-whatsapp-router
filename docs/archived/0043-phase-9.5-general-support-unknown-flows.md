# Phase 9.5 — General Support & Unknown Flows

## Context

The project has four flows registered: `unknown`, `general_support`, `digital_certificate`, `billing`. The latter two are fully implemented with subroutes, LLM extraction, retry logic, and confirmation steps. The `unknown` flow is already well-implemented with conversational LLM (matches `CLAUDE.md` spec). The `general_support` flow is a bare-bones stub — it immediately escalates to a human without offering the user a choice or summarizing their problem via LLM.

This plan enhances `general_support` to match the `FLOWS.md` specification.

## Unknown Flow — No Changes Needed

Already implements per `CLAUDE.md`:

- Conversational LLM (`jsonMode: false`) for natural replies
- `classifyFlow()` each turn to detect intent → `_handoff_flow` handoff
- Static menu fallback after 5 turns (`MAX_TURNS`)
- Graceful LLM error handling

## General Support Flow — Enhance

**Current state (2 steps, no LLM):**

- `start` → asks for problem
- `awaiting_problem` → truncates text to 100 chars, immediately ends (`done: true`)

**Target state (3 steps, with LLM summary + handoff offer):**

- `start` → asks for problem
- `awaiting_problem` → captures problem, calls LLM for topic summary, offers human handoff (sim/não)
- `awaiting_handoff` → handles sim/não, generates protocol if yes, ends flow

---

## Files to Modify

### 1. `src/lib/llm/prompts.ts` — Add topic summary prompt

Add two functions:

- **`generalSupportSummarySystemPrompt()`** — instructs LLM to summarize user's problem in max 50 chars, Portuguese, plain text (no JSON)
- **`generalSupportSummaryUserPrompt(text: string)`** — passes problem text

Uses `jsonMode: false` and `maxTokens: 100` (short output).

### 2. `src/lib/flows/generalSupport/helpers.ts` — New file

- **`generateProtocolId(): string`** — format `GS-YYYYMMDD-XXXX` (same pattern as `src/lib/flows/digitalCertificate/helpers.ts:9-19`)
- **`detectConfirmation(text: string): "yes" | "no" | "unclear"`** — sim/não regex (same pattern as `src/lib/flows/digitalCertificate/helpers.ts:55-63`)

### 3. `src/lib/flows/generalSupport/steps.ts` — Rewrite

**`handleStart`** (unchanged behavior, updated message):

- reply: "Como posso ajudar você?\n\nPor favor, descreva sua dúvida ou problema."
- `nextStep: "awaiting_problem"`

**`handleAwaitingProblem`** (new behavior):

1. Store `data.problem = message.text`
2. Call `callLlm()` with summary prompt (`jsonMode: false`, `maxTokens: 100`)
3. Build reply: "Entendo que você precisa de ajuda com [summary].\n\nPara melhor atendê-lo, posso transferir você para um atendente humano.\n\nDeseja falar com um atendente? (sim/não)"
4. If LLM fails: use truncated problem text as fallback summary
5. `nextStep: "awaiting_handoff"`

**`handleAwaitingHandoff`** (new step):

1. Call `detectConfirmation(message.text)`
2. If `"yes"`: generate protocol, reply with handoff confirmation, `done: true`, store `{ protocol_id, handoff_requested: true, handoff_at }`
3. If `"no"`: reply "Obrigado! Se precisar de mais ajuda, é só me chamar.", `done: true`
4. If `"unclear"`: reply "Por favor, responda sim ou não. Deseja falar com um atendente?", stay on `awaiting_handoff`

### 4. `src/lib/flows/generalSupport/flow.ts` — Update registration

Register 3 steps: `start`, `awaiting_problem`, `awaiting_handoff`

---

## Reply Templates (Brazilian Portuguese)

**Handoff confirmation:**

> Entendido! Vou transferir você para um atendente humano.
> Seu protocolo de atendimento: [GS-YYYYMMDD-XXXX]
> Um atendente entrará em contato em breve pelo WhatsApp.

**No handoff:**

> Obrigado! Se precisar de mais ajuda, é só me chamar.

---

## Verification

1. `npm run build` — TypeScript compiles without errors
2. `npm run lint` — No lint errors
3. Manual test: trigger `general_support` via global router ("preciso de ajuda", "quero falar com alguém") and walk through all 3 steps (describe problem → sim/não → end)
